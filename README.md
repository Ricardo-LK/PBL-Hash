# An√°lise de Desempenho de Tabelas Hash em Java

## Descri√ß√£o do Projeto

Este projeto implementa e analisa o desempenho de diferentes abordagens de tabelas hash em Java, comparando estrat√©gias de **rehashing** e **encadeamento** com diferentes fun√ß√µes hash. O estudo avalia o comportamento dessas estruturas de dados frente a diferentes tamanhos de vetor e volumes de dados, seguindo rigorosamente os requisitos especificados.

## Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ src/                    # C√≥digo fonte Java
‚îÇ   ‚îú‚îÄ‚îÄ Main.java          # Classe principal para execu√ß√£o dos testes
‚îÇ   ‚îú‚îÄ‚îÄ Registro.java      # Classe que representa um registro com c√≥digo de 9 d√≠gitos
‚îÇ   ‚îú‚îÄ‚îÄ Hash.java          # Classe base para implementa√ß√µes de hash
‚îÇ   ‚îú‚îÄ‚îÄ HashRehashing.java # Implementa√ß√£o com rehashing (linear/quadr√°tico)
‚îÇ   ‚îú‚îÄ‚îÄ HashDuplo.java     # Implementa√ß√£o com hash duplo
‚îÇ   ‚îú‚îÄ‚îÄ HashEncadeamento.java # Implementa√ß√£o com encadeamento
‚îÇ   ‚îî‚îÄ‚îÄ EstatisticaHash.java # Classe para coleta de estat√≠sticas
‚îÇ
‚îú‚îÄ‚îÄ plots/                # Scripts e resultados de an√°lise
‚îÇ   ‚îú‚îÄ‚îÄ plots/ 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plot.py           # Script Python para gera√ß√£o de gr√°ficos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt  # Depend√™ncias do Python
‚îÇ   ‚îî‚îÄ‚îÄ [tamanhos]/       # Diret√≥rios com resultados para cada tamanho
‚îî‚îÄ‚îÄ out/                  # Arquivos compilados
```

## Implementa√ß√µes de Tabela Hash

### 1. Hash com Rehashing Linear/Quadr√°tico (`HashRehashing.java`)
- **Fun√ß√£o Hash Principal**: XOR com shift right 16 bits + m√≥dulo
- **Estrat√©gia de Rehashing**: Quadr√°tica (i¬≤)
- **Tratamento de Colis√µes**: Busca por posi√ß√£o vazia no vetor usando rehashing quadr√°tico
- **F√≥rmula**: `hash = (hash1 + tentativa¬≤) % modulo`

### 2. Hash Duplo (`HashDuplo.java`)
- **Primeira Fun√ß√£o Hash**: XOR com shift right 16 bits + m√≥dulo
- **Segunda Fun√ß√£o Hash**: `1 + (dado % (tamanhoTabelaHash - 1))` (hash duplo cl√°ssico)
- **Estrat√©gia**: `hash = (hash1 + tentativa * hash2) % modulo`
- **Vantagem**: Distribui√ß√£o mais uniforme que rehashing linear/quadr√°tico

### 3. Hash com Encadeamento (`HashEncadeamento.java`)
- **Fun√ß√£o Hash**: XOR com shift right 16 bits + m√≥dulo
- **Estrat√©gia**: Listas encadeadas em cada bucket
- **Caracter√≠stica**: Capacidade ilimitada de elementos
- **Tratamento de Colis√µes**: Encadeamento na mesma posi√ß√£o

## Par√¢metros do Estudo

### Tamanhos do Vetor Hash
- **Pequeno**: 1.000 posi√ß√µes
- **M√©dio**: 10.000 posi√ß√µes  
- **Grande**: 100.000 posi√ß√µes

### Conjuntos de Dados
- **Pequeno**: 1.000 registros
- **M√©dio**: 10.000 registros  
- **Grande**: 100.000 registros

**Seed Utilizada**: `2025` (para garantir reproduibilidade dos testes)

**Faixa de Dados**: N√∫meros inteiros de 1 a 2.147.483.647

## M√©tricas Avaliadas

### 1. Tempo de Inser√ß√£o
- Tempo total para inserir todos os elementos
- Medido em nanossegundos (ns)
- Coletado usando `System.nanoTime()`

### 2. Tempo de Busca
- Tempo total para buscar todos os elementos
- Medido em nanossegundos (ns)
- Inclui buscas bem-sucedidas e mal-sucedidas

### 3. N√∫mero de Colis√µes
- **Para Rehashing/Hash Duplo**: N√∫mero de tentativas de rehashing necess√°rias
- **Para Encadeamento**: N√∫mero de elementos al√©m do primeiro em cada bucket + travessias durante inser√ß√£o

### 4. An√°lise de Distribui√ß√£o
- **Tr√™s Maiores Listas**: Para encadeamento, tamanho das tr√™s maiores listas
- **Gaps**: Menor, maior e m√©dia de espa√ßos vazios entre elementos no vetor
- **Quantidade de Gaps**: N√∫mero total de sequ√™ncias vazias na tabela

### 5. Efici√™ncia de Busca
- **Buscas Bem-sucedidas**: Elementos encontrados na tabela
- **Buscas Mal-sucedidas**: Elementos n√£o encontrados

## Metodologia Experimental

### Configura√ß√£o dos Testes
- **Ambiente**: Java SE
- **Medi√ß√µes**: 9 combina√ß√µes (3 tamanhos de tabela √ó 3 tamanhos de dados)
- **Repeti√ß√£o**: 3 fun√ß√µes hash diferentes para cada combina√ß√£o
- **Consist√™ncia**: Mesmos conjuntos de dados para todas as fun√ß√µes hash

### Processo de Coleta
1. Gera√ß√£o de dados com seed fixa
2. Limpeza da tabela hash entre testes
3. Medi√ß√£o precisa de tempos com `nanoTime()`
4. Coleta abrangente de estat√≠sticas
5. Exporta√ß√£o automatizada para CSV

## Resultados Detalhados Baseados nos Dados Emp√≠ricos

### An√°lise por Tamanho de Tabela Hash

#### Tabela Pequena (100.000 posi√ß√µes)

![Tempo de Inser√ß√£o - 100000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/100000_tempoInsercao.png)
![Tempo de Busca - 100000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/100000_tempoBusca.png)
![Colis√µes - 100000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/100000_colisoes.png)
![Maior Gap - 100000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/100000_maiorGap.png)
![Menor Gap - 100000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/100000_menorGap.png)
![Media Gap - 100000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/100000_mediaGap.png)

**Resultados Emp√≠ricos Detalhados**

### Tabela 100.000 posi√ß√µes com 100.000 dados:

**Tempo de Inser√ß√£o (ns)**:
- **HashRehashing**: 41.35ms
- **HashEncadeamento**: 16.92ms
- **HashDuplo**: 18.66ms

**Tempo de Busca (ns)**:
- **HashRehashing**: 20.77ms
- **HashEncadeamento**: 4.24ms
- **HashDuplo**: 10.58ms

**Colis√µes**:
- **HashRehashing**: 159.238 colis√µes
- **HashEncadeamento**: 99.215 colis√µes
- **HashDuplo**: 168.697 colis√µes

**Maior Gap**:
- **HashRehashing**: 6 posi√ß√µes
- **HashEncadeamento**: 11 posi√ß√µes  
- **HashDuplo**: 5 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 1.21 posi√ß√µes
- **HashEncadeamento**: 1.58 posi√ß√µes
- **HashDuplo**: 1.11 posi√ß√µes

### Tabela 100.000 posi√ß√µes com 1.000.000 dados:

**Tempo de Inser√ß√£o (ns)**:
- **HashRehashing**: 27.19ms
- **HashEncadeamento**: 626.12ms
- **HashDuplo**: 9.70ms

**Tempo de Busca (ns)**:
- **HashRehashing**: 233.44ms
- **HashEncadeamento**: 147.15ms
- **HashDuplo**: 114.14ms

**Colis√µes**:
- **HashRehashing**: 159.790 colis√µes
- **HashEncadeamento**: 9.989.186 colis√µes
- **HashDuplo**: 140.452 colis√µes

**Maior Gap**:
- **HashRehashing**: 7 posi√ß√µes
- **HashEncadeamento**: 1 posi√ß√µes
- **HashDuplo**: 5 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 1.21 posi√ß√µes
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1.11 posi√ß√µes

### Tabela 100.000 posi√ß√µes com 10.000.000 dados:

**Tempo de Inser√ß√£o (ns)**:
- **HashRehashing**: 19.05ms
- **HashEncadeamento**: 27085.93ms
- **HashDuplo**: 10.21ms

**Tempo de Busca (ns)**:
- **HashRehashing**: 917.44ms
- **HashEncadeamento**: 18883.33ms
- **HashDuplo**: 1171.88ms

**Colis√µes**:
- **HashRehashing**: 161.798 colis√µes
- **HashEncadeamento**: 996.848.624 colis√µes
- **HashDuplo**: 168.167 colis√µes

**Maior Gap**:
- **HashRehashing**: 8 posi√ß√µes
- **HashEncadeamento**: 0 posi√ß√µes
- **HashDuplo**: 5 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 0 posi√ß√µes
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 1.20 posi√ß√µes
- **HashEncadeamento**: 0 posi√ß√µes
- **HashDuplo**: 1.11 posi√ß√µes

## An√°lise de Performance Comparativa Tabela 100.000

### Desempenho por Cen√°rio de Carga

No cen√°rio balanceado, onde a tabela possui 100.000 posi√ß√µes para 100.000 dados, o Hash por Encadeamento demonstra superioridade indiscut√≠vel. Seu tempo de inser√ß√£o de 16,92 milissegundos e tempo de busca de apenas 4,24 milissegundos representam a melhor performance geral entre todas as implementa√ß√µes testadas. O Hash Duplo apresenta performance equilibrada com 18,66 milissegundos para inser√ß√£o e 10,58 milissegundos para busca, enquanto o Hash com Rehashing mostra defici√™ncias significativas com 41,35 milissegundos na inser√ß√£o e 20,77 milissegundos na busca.

Quando submetemos as implementa√ß√µes a um cen√°rio de overload moderado, com 1.000.000 de dados para 100.000 posi√ß√µes, observamos uma mudan√ßa dr√°stica no panorama de performance. O Hash Duplo assume a lideran√ßa com not√°veis 9,70 milissegundos para inser√ß√£o e 114,14 milissegundos para busca. O Hash com Rehashing mostra melhoria relativa na inser√ß√£o, reduzindo para 27,19 milissegundos. Entretanto, o Hash por Encadeamento sofre um colapso catastr√≥fico na performance, com tempo de inser√ß√£o explodindo para 626,12 milissegundos - aproximadamente 37 vezes mais lento que no cen√°rio balanceado.

No cen√°rio de overload extremo, com 10.000.000 de dados para as mesmas 100.000 posi√ß√µes, o Hash Duplo mant√©m sua estabilidade com 10,21 milissegundos para inser√ß√£o. O Hash com Rehashing continua apresentando performance consistente na inser√ß√£o com 19,05 milissegundos. O Hash por Encadeamento, no entanto, experimenta uma degrada√ß√£o inaceit√°vel, atingindo 27.085,93 milissegundos na inser√ß√£o e 18.883,33 milissegundos na busca, tornando-se praticamente inutiliz√°vel para aplica√ß√µes que demandam performance.

### An√°lise de Escalabilidade e Comportamento

A an√°lise de escalabilidade revela padr√µes distintos entre as implementa√ß√µes. O Hash por Encadeamento, embora excelente em cen√°rios balanceados, sofre de degrada√ß√£o exponencial sob carga elevada. Seu n√∫mero de colis√µes aumenta dramaticamente de 99.215 para 996.848.624, demonstrando que as listas encadeadas tornam-se excessivamente longas e ineficientes sob condi√ß√µes de overload.

O Hash Duplo emerge como a implementa√ß√£o mais escal√°vel, mantendo performance consistente across todos os cen√°rios. Suas colis√µes permanecem est√°veis em torno de 168.000, independentemente do n√≠vel de overload, gra√ßas √† dupla fun√ß√£o hash que distribui a carga de maneira mais uniforme pela tabela.

O Hash com Rehashing apresenta um comportamento interessante: enquanto sua performance de inser√ß√£o melhora com o aumento do overload, o tempo de busca degrada significativamente, indo de 20,77 milissegundos para 917,44 milissegundos no cen√°rio de overload extremo.

### An√°lise de Distribui√ß√£o e Efici√™ncia

A distribui√ß√£o espacial analisada atrav√©s dos gaps revela que o Hash Duplo mant√©m a distribui√ß√£o mais consistente, com gap m√©dio de aproximadamente 1,11 posi√ß√µes em todos os cen√°rios. O Hash por Encadeamento tende a uma distribui√ß√£o perfeita sob alta carga, com gap m√©dio chegando a zero no cen√°rio de overload extremo, embora essa distribui√ß√£o ideal n√£o se traduza em boa performance devido ao custo do tratamento de colis√µes.

#### Tabela M√©dia (1.000.000 posi√ß√µes)

![Tempo de Inser√ß√£o - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/1000000_tempoInsercao.png)
![Tempo de Busca - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/1000000_tempoBusca.png)
![Colis√µes - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/1000000_colisoes.png)
![Maior Gap - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/1000000_maiorGap.png)
![Menor Gap - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/1000000_menorGap.png)
![Media Gap - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/1000000_mediaGap.png)

**Resultados Emp√≠ricos Detalhados - Tabela 1.000.000 posi√ß√µes**

### Tabela 1.000.000 posi√ß√µes com 100.000 dados:

**Tempo de Inser√ß√£o (ms)**:
- **HashRehashing**: 9,52ms
- **HashEncadeamento**: 5,14ms
- **HashDuplo**: 7,83ms

**Tempo de Busca (ms)**:
- **HashRehashing**: 7,08ms
- **HashEncadeamento**: 1,55ms
- **HashDuplo**: 2,49ms

**Colis√µes**:
- **HashRehashing**: 5.507 colis√µes
- **HashEncadeamento**: 9.927 colis√µes
- **HashDuplo**: 5.341 colis√µes

**Maior Gap**:
- **HashRehashing**: 116 posi√ß√µes
- **HashEncadeamento**: 116 posi√ß√µes
- **HashDuplo**: 109 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 10,46 posi√ß√µes
- **HashEncadeamento**: 10,51 posi√ß√µes
- **HashDuplo**: 10,00 posi√ß√µes

### Tabela 1.000.000 posi√ß√µes com 1.000.000 dados:

**Tempo de Inser√ß√£o (ms)**:
- **HashRehashing**: 217,59ms
- **HashEncadeamento**: 124,44ms
- **HashDuplo**: 111,11ms

**Tempo de Busca (ms)**:
- **HashRehashing**: 206,01ms
- **HashEncadeamento**: 44,59ms
- **HashDuplo**: 110,05ms

**Colis√µes**:
- **HashRehashing**: 1.610.524 colis√µes
- **HashEncadeamento**: 995.976 colis√µes
- **HashDuplo**: 1.412.527 colis√µes

**Maior Gap**:
- **HashRehashing**: 8 posi√ß√µes
- **HashEncadeamento**: 15 posi√ß√µes
- **HashDuplo**: 6 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 1,21 posi√ß√µes
- **HashEncadeamento**: 1,58 posi√ß√µes
- **HashDuplo**: 1,11 posi√ß√µes

### Tabela 1.000.000 posi√ß√µes com 10.000.000 dados:

**Tempo de Inser√ß√£o (ms)**:
- **HashRehashing**: 137,89ms
- **HashEncadeamento**: 6008,74ms
- **HashDuplo**: 123,94ms

**Tempo de Busca (ms)**:
- **HashRehashing**: 2191,87ms
- **HashEncadeamento**: 2672,24ms
- **HashDuplo**: 2154,29ms

**Colis√µes**:
- **HashRehashing**: 1.613.104 colis√µes
- **HashEncadeamento**: 99.669.638 colis√µes
- **HashDuplo**: 1.431.484 colis√µes

**Maior Gap**:
- **HashRehashing**: 9 posi√ß√µes
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 6 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 1,20 posi√ß√µes
- **HashEncadeamento**: 1,00 posi√ß√£o
- **HashDuplo**: 1,11 posi√ß√µes

## An√°lise de Performance Comparativa Tabela 1.000.000

### Desempenho por Cen√°rio de Carga

No cen√°rio de baixa densidade, onde a tabela possui 1.000.000 de posi√ß√µes para apenas 100.000 dados, o Hash por Encadeamento demonstra performance superior tanto na inser√ß√£o (5,14ms) quanto na busca (1,55ms). O Hash Duplo apresenta performance intermedi√°ria com 7,83ms para inser√ß√£o e 2,49ms para busca, enquanto o Hash com Rehashing mostra os piores resultados com 9,52ms na inser√ß√£o e 7,08ms na busca.

No cen√°rio balanceado ideal, com 1.000.000 de dados para 1.000.000 de posi√ß√µes, observamos uma distribui√ß√£o mais equilibrada de performance. O Hash por Encadeamento mant√©m sua lideran√ßa na busca com impressionantes 44,59ms, enquanto na inser√ß√£o o Hash Duplo assume vantagem com 111,11ms contra 124,44ms do Encadeamento e 217,59ms do Rehashing.

Quando submetemos as implementa√ß√µes a um cen√°rio de overload (10.000.000 dados para 1.000.000 posi√ß√µes), o panorama muda drasticamente. O Hash Duplo emerge como o mais eficiente na inser√ß√£o com apenas 123,94ms, seguido pelo Hash com Rehashing com 137,89ms. O Hash por Encadeamento sofre uma degrada√ß√£o catastr√≥fica, com tempo de inser√ß√£o explodindo para 6008,74ms - aproximadamente 48 vezes mais lento que o Hash Duplo.

### An√°lise de Escalabilidade e Comportamento

A an√°lise de escalabilidade na tabela de 1.000.000 posi√ß√µes revela padr√µes consistentes com a an√°lise anterior, por√©m com algumas particularidades importantes. O Hash por Encadeamento mant√©m sua excelente performance em cen√°rios de baixa e m√©dia densidade, mas demonstra completa falta de escalabilidade sob condi√ß√µes de overload extremo.

O Hash Duplo consolida-se como a implementa√ß√£o mais consistente across todos os cen√°rios, especialmente na inser√ß√£o onde mant√©m tempos est√°veis mesmo sob carga dez vezes superior √† capacidade da tabela. Sua performance de 123,94ms no cen√°rio de overload √© notavelmente pr√≥xima √† do cen√°rio balanceado (111,11ms).

O Hash com Rehashing apresenta um comportamento peculiar: seu tempo de inser√ß√£o melhora significativamente do cen√°rio balanceado (217,59ms) para o cen√°rio de overload (137,89ms), sugerindo que o mecanismo de rehashing torna-se mais eficiente quando a tabela est√° sob alta press√£o.

### An√°lise de Distribui√ß√£o e Efici√™ncia

A distribui√ß√£o espacial analisada atrav√©s dos gaps revela padr√µes interessantes. No cen√°rio de baixa densidade, todos os m√©todos apresentam gaps m√©dios elevados (em torno de 10 posi√ß√µes), refletindo a dispers√£o natural em uma tabela pouco ocupada.

√Ä medida que a densidade aumenta, os gaps m√©dios convergem para valores pr√≥ximos de 1, indicando distribui√ß√£o quase ideal. O Hash por Encadeamento atinge distribui√ß√£o perfeita (gap m√©dio de 1,00) no cen√°rio de overload, enquanto o Hash Duplo mant√©m consist√™ncia not√°vel com gap m√©dio de 1,11 em todos os cen√°rios de m√©dia e alta densidade.

O n√∫mero de colis√µes segue padr√£o esperado: o Hash por Encadeamento apresenta menor n√∫mero de colis√µes no cen√°rio balanceado, mas sofre aumento exponencial sob overload (99,6 milh√µes de colis√µes). J√° o Hash Duplo e Rehashing mant√™m n√∫meros de colis√µes relativamente est√°veis independentemente da carga.

### Conclus√µes Espec√≠ficas para Tabela 1.000.000

A tabela maior (1.000.000 vs 100.000 posi√ß√µes) demonstra melhor capacidade de absorver carga sem degrada√ß√£o severa de performance. Enquanto na tabela menor o Hash por Encadeamento tornava-se inutiliz√°vel sob overload, na tabela maior ele ainda mant√©m performance aceit√°vel na busca mesmo com carga 10x superior.

O Hash Duplo confirma sua superioridade como solu√ß√£o mais balanceada, oferecendo boa performance em todos os cen√°rios e excelente escalabilidade. O Hash com Rehashing mostra melhorias significativas em rela√ß√£o √† tabela menor, especialmente na inser√ß√£o sob alta carga.

Esta an√°lise refor√ßa que a escolha do m√©todo de hash ideal depende criticamente do cen√°rio de uso esperado e da rela√ß√£o entre tamanho da tabela e volume de dados a ser armazenado.
#### Tabela Grande (10.000.000 posi√ß√µes)

![Tempo de Inser√ß√£o - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/10000000_tempoInsercao.png)
![Tempo de Busca - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/10000000_tempoBusca.png)
![Colis√µes - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/10000000_colisoes.png)
![Maior Gap - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/10000000_maiorGap.png)
![Menor Gap - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/10000000_menorGap.png)
![Media Gap - 10000000](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/10000000_mediaGap.png)

**Resultados Emp√≠ricos Detalhados - Tabela 10.000.000 posi√ß√µes**

### Tabela 10.000.000 posi√ß√µes com 100.000 dados:

**Tempo de Inser√ß√£o (ms)**:
- **HashRehashing**: 10,22ms
- **HashEncadeamento**: 14,81ms
- **HashDuplo**: 10,58ms

**Tempo de Busca (ms)**:
- **HashRehashing**: 2,26ms
- **HashEncadeamento**: 1,91ms
- **HashDuplo**: 2,87ms

**Colis√µes**:
- **HashRehashing**: 464 colis√µes
- **HashEncadeamento**: 921 colis√µes
- **HashDuplo**: 464 colis√µes

**Maior Gap**:
- **HashRehashing**: 1.191 posi√ß√µes
- **HashEncadeamento**: 1.191 posi√ß√µes
- **HashDuplo**: 1.191 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 100,48 posi√ß√µes
- **HashEncadeamento**: 100,49 posi√ß√µes
- **HashDuplo**: 100,02 posi√ß√µes

### Tabela 10.000.000 posi√ß√µes com 1.000.000 dados:

**Tempo de Inser√ß√£o (ms)**:
- **HashRehashing**: 162,40ms
- **HashEncadeamento**: 161,53ms
- **HashDuplo**: 205,18ms

**Tempo de Busca (ms)**:
- **HashRehashing**: 33,93ms
- **HashEncadeamento**: 28,16ms
- **HashDuplo**: 56,63ms

**Colis√µes**:
- **HashRehashing**: 54.828 colis√µes
- **HashEncadeamento**: 99.328 colis√µes
- **HashDuplo**: 53.403 colis√µes

**Maior Gap**:
- **HashRehashing**: 139 posi√ß√µes
- **HashEncadeamento**: 139 posi√ß√µes
- **HashDuplo**: 139 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 10,46 posi√ß√µes
- **HashEncadeamento**: 10,52 posi√ß√µes
- **HashDuplo**: 10,01 posi√ß√µes

### Tabela 10.000.000 posi√ß√µes com 10.000.000 dados:

**Tempo de Inser√ß√£o (ms)**:
- **HashRehashing**: 2.439,35ms
- **HashEncadeamento**: 2.165,39ms
- **HashDuplo**: 2.839,34ms

**Tempo de Busca (ms)**:
- **HashRehashing**: 1.933,63ms
- **HashEncadeamento**: 659,90ms
- **HashDuplo**: 2.605,37ms

**Colis√µes**:
- **HashRehashing**: 16.091.601 colis√µes
- **HashEncadeamento**: 9.949.762 colis√µes
- **HashDuplo**: 15.007.236 colis√µes

**Maior Gap**:
- **HashRehashing**: 11 posi√ß√µes
- **HashEncadeamento**: 15 posi√ß√µes
- **HashDuplo**: 7 posi√ß√µes

**Menor Gap**:
- **HashRehashing**: 1 posi√ß√£o
- **HashEncadeamento**: 1 posi√ß√£o
- **HashDuplo**: 1 posi√ß√£o

**M√©dia Gap**:
- **HashRehashing**: 1,20 posi√ß√µes
- **HashEncadeamento**: 1,58 posi√ß√µes
- **HashDuplo**: 1,11 posi√ß√µes

## An√°lise de Performance Comparativa Tabela 10.000.000

### Desempenho por Cen√°rio de Carga

No cen√°rio de baixa densidade (100.000 dados em 10 milh√µes de posi√ß√µes), observamos uma distribui√ß√£o interessante de performance. O Hash por Encadeamento demonstra a melhor efici√™ncia na busca com 1,91ms, enquanto HashRehashing e HashDuplo apresentam performance muito similar na inser√ß√£o (‚âà10,4ms). O HashDuplo mostra ligeira desvantagem na busca com 2,87ms.

No cen√°rio de m√©dia densidade (1 milh√£o de dados), as tr√™s implementa√ß√µes apresentam performance bastante equilibrada na inser√ß√£o, com HashEncadeamento (161,53ms) e HashRehashing (162,40ms) virtualmente empatados, e HashDuplo ligeiramente atr√°s (205,18ms). Na busca, o HashEncadeamento mant√©m lideran√ßa com 28,16ms, seguido por HashRehashing (33,93ms) e HashDuplo (56,63ms).

No cen√°rio de alta densidade (tabela completamente preenchida com 10 milh√µes de dados), o HashEncadeamento emerge como claro vencedor, alcan√ßando o melhor desempenho tanto na inser√ß√£o (2.165,39ms) quanto na busca (659,90ms). O HashRehashing apresenta performance intermedi√°ria, enquanto o HashDuplo demonstra os piores resultados neste cen√°rio espec√≠fico.

### An√°lise de Escalabilidade e Comportamento

A tabela de 10 milh√µes de posi√ß√µes revela padr√µes de escalabilidade distintos dos observados nas tabelas menores. Diferente do comportamento anterior, onde o HashDuplo se destacava sob overload, nesta configura√ß√£o maior o HashEncadeamento demonstra excelente escalabilidade, mantendo performance superior mesmo quando a tabela est√° completamente preenchida.

O HashRehashing mostra comportamento consistente, com degrada√ß√£o gradual de performance conforme a densidade aumenta. Seu tempo de inser√ß√£o cresce de forma aproximadamente linear com o aumento da carga.

O HashDuplo, que anteriormente se mostrava como a solu√ß√£o mais escal√°vel, nesta configura√ß√£o maior apresenta a pior performance no cen√°rio de alta densidade, sugerindo que seu mecanismo de hash duplo pode sofrer com clusters de colis√µes em tabelas muito grandes quando completamente preenchidas.

### An√°lise de Distribui√ß√£o e Efici√™ncia

A an√°lise de distribui√ß√£o espacial na tabela gigante revela padr√µes fascinantes. Nos cen√°rios de baixa e m√©dia densidade, os gaps m√©dios s√£o extremamente elevados (100,48 e 10,46 posi√ß√µes respectivamente para HashRehashing), refletindo a enorme dispers√£o em uma tabela esparsamente povoada.

Conforme a tabela se aproxima da capacidade total, os gaps convergem para valores pr√≥ximos de 1, indicando distribui√ß√£o quase ideal. O HashDuplo mant√©m sua caracter√≠stica de melhor distribui√ß√£o com gap m√©dio de 1,11 posi√ß√µes, seguido pelo HashRehashing (1,20) e HashEncadeamento (1,58).

O n√∫mero de colis√µes segue padr√£o consistente: HashEncadeamento apresenta significativamente menos colis√µes (9,9 milh√µes) no cen√°rio de alta densidade comparado aos outros m√©todos (16,1 e 15,0 milh√µes), o que explica sua performance superior neste cen√°rio espec√≠fico.

### Conclus√µes Espec√≠ficas para Tabela 10.000.000

A tabela de 10 milh√µes de posi√ß√µes apresenta din√¢mica fundamentalmente diferente das tabelas menores. O enorme espa√ßo dispon√≠vel permite que o HashEncadeamento brilhe, especialmente em cen√°rios de alta densidade onde sua efici√™ncia no tratamento de colis√µes atrav√©s de listas encadeadas se mostra superior.

A performance relativa dos m√©todos inverte-se em compara√ß√£o com tabelas menores: enquanto em tabelas pequenas sob overload o HashDuplo era superior, na tabela gigante completamente preenchida o HashEncadeamento domina claramente.

Esta an√°lise demonstra que o tamanho absoluto da tabela hash √© um fator cr√≠tico na escolha do m√©todo ideal. Para aplica√ß√µes que requerem tabelas muito grandes com alta taxa de ocupa√ß√£o, o Hash por Encadeamento pode ser a escolha mais eficiente, enquanto para tabelas menores ou com flutua√ß√µes significativas de carga, o Hash Duplo mant√©m vantagens em termos de consist√™ncia.

O HashRehashing posiciona-se como uma solu√ß√£o balanceada, oferecendo performance competitiva dentre todos os cen√°rios sem se destacar em nenhum espec√≠fico, representando uma escolha segura para aplica√ß√µes com requisitos vari√°veis.

### An√°lise Comparativa Geral

![Comparativo Tempo de Inser√ß√£o](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/comparativo_tempoInsercao.png)
![Comparativo Tempo de Busca](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/comparativo_tempoBusca.png)
![Comparativo Colis√µes](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/comparativo_colisoes.png)
![Comparativo Maior Gap](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/comparativo_maiorGap.png)
![Comparativo Menor Gap](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/comparativo_menorGap.png)
![Comparativo Media Gap](https://raw.githubusercontent.com/Ricardo-LK/PBL-Hash/refs/heads/main/plots/plots/comparativo_mediaGap.png)

## An√°lise de Desempenho Detalhada Baseada em Dados Reais

### Tabela Comparativa de Performance com Dados Emp√≠ricos

| M√©trica | Tamanho | HashRehashing | HashEncadeamento | HashDuplo | Vencedor | Fator de Melhoria |
|---------|---------|---------------|------------------|-----------|----------|-------------------|
| **Inser√ß√£o (ns)** | 1.000 | 132.193 | 114.741 | **29.975** | HashDuplo | 4.4√ó |
| **Inser√ß√£o (ns)** | 10.000 | 2.082.388 | 2.300.149 | **1.859.799** | HashDuplo | 1.1√ó |
| **Inser√ß√£o (ns)** | 100.000 | 42.855.681 | **8.710.984** | 3.144.902.200 | Encadeamento | 4.9√ó |
| **Busca (ns)** | 1.000 | 112.437 | **19.687** | 139.296 | Encadeamento | 5.7√ó |
| **Busca (ns)** | 10.000 | 1.629.636 | **631.281** | 2.923.134 | Encadeamento | 2.6√ó |
| **Busca (ns)** | 100.000 | 32.266.816 | **3.765.222** | 4.270.411.300 | Encadeamento | 8.6√ó |
| **Colis√µes** | 1.000 | **52** | 94 | **52** | Rehashing/Duplo | - |
| **Colis√µes** | 10.000 | 154.136 | **10.144** | 190.744 | Encadeamento | 15.2√ó |
| **Colis√µes** | 100.000 | 2.243.940 | **99.673** | 2.550.075 | Encadeamento | 22.5√ó |

### An√°lise de Comportamento por Fator de Carga

**Fator de Carga (Œ±) = n/m**

#### Œ± = 1.0 (1.000 elementos em 1.000 posi√ß√µes)
- **HashDuplo**: Excelente performance em inser√ß√£o (29.975 ns)
- **Encadeamento**: Dominante em buscas (19.687 ns)
- **Rehashing**: Performance equilibrada (132.193 ns inser√ß√£o, 112.437 ns busca)
- **Colis√µes**: M√≠nimas para todas as estrat√©gias (52-94)

#### Œ± = 1.0 (10.000 elementos em 10.000 posi√ß√µes)  
- **HashDuplo**: Mant√©m vantagem em inser√ß√£o (1.859.799 ns)
- **Encadeamento**: Consolida lideran√ßa em buscas (631.281 ns)
- **Rehashing**: Aumento significativo de colis√µes (154.136)
- **Distribui√ß√£o**: Melhora significativamente (maior gap: 89 vs 797)

#### Œ± = 1.0 (100.000 elementos em 100.000 posi√ß√µes)
- **HashDuplo**: **Degrada√ß√£o catastr√≥fica** (3.14 segundos inser√ß√£o)
- **Encadeamento**: Performance consistente e robusta (8.7ms inser√ß√£o)
- **Rehashing**: Degrada√ß√£o moderada (42.8ms inser√ß√£o)
- **Colis√µes**: Encadeamento mant√©m vantagem significativa (99.673 vs 2.2-2.5 milh√µes)

## An√°lise de Comportamentos An√¥malos e Insights Cr√≠ticos

### Degrada√ß√£o Catastr√≥fica do Hash Duplo
O comportamento extremo do HashDuplo com 100.000 elementos (3.144.902.200 ns) sugere um dos seguintes cen√°rios:

1. **Clusteriza√ß√£o Secund√°ria Severa**: As duas fun√ß√µes hash podem estar gerando padr√µes que se refor√ßam negativamente
2. **Problema de Implementa√ß√£o**: Poss√≠vel loop infinito ou condi√ß√£o de t√©rmino inadequada no rehashing
3. **M√° Distribui√ß√£o**: A segunda fun√ß√£o hash pode n√£o estar fornecendo saltos suficientemente diferentes
4. **Sensibilidade ao Tamanho**: O algoritmo pode ser particularmente sens√≠vel a tabelas maiores

### Performance Consistente do Encadeamento
O encadeamento demonstrou a **menor variabilidade de performance** entre diferentes tamanhos de tabela:
- Varia√ß√£o de inser√ß√£o: 114.741 ns to 8.710.984 ns (76√ó)
- Varia√ß√£o de busca: 19.687 ns to 3.765.222 ns (191√ó)
- Compare com HashDuplo: 29.975 ns to 3.144.902.200 ns (104,857√ó)

### Evolu√ß√£o dos Padr√µes de Distribui√ß√£o (Gaps)
A an√°lise dos maiores gaps revela padr√µes fascinantes:

| Tamanho | HashRehashing | HashEncadeamento | HashDuplo | Interpreta√ß√£o |
|---------|---------------|------------------|-----------|---------------|
| 1.000 | 797 | 797 | 797 | Distribui√ß√£o pobre, grandes √°reas vazias |
| 10.000 | 89 | 89 | 89 | Melhora significativa na distribui√ß√£o |
| 100.000 | 1 | 11 | 1 | Distribui√ß√£o quase perfeita |

## An√°lise de Complexidade Pr√°tica vs Te√≥rica

### Hash com Encadeamento
- **Complexidade Te√≥rica**: O(1 + Œ±) onde Œ± = n/m
- **Complexidade Pr√°tica Observada**: O(1) para Œ± ‚â§ 10, degrada√ß√£o gradual ap√≥s
- **Vantagem Pr√°tica**: N√£o sofre degrada√ß√£o catastr√≥fica com Œ± ‚â• 1.0
- **Robustez**: Performance mais previs√≠vel atrav√©s de diferentes cen√°rios

### Hash com Rehashing
- **Complexidade Te√≥rica**: O(1/(1-Œ±)) para Œ± < 1.0
- **Complexidade Pr√°tica Observada**: O(n) para Œ± ‚âà 1.0, degrada√ß√£o controlada
- **Limita√ß√£o Pr√°tica**: Performance aceit√°vel apenas para Œ± ‚â§ 1.0
- **Comportamento**: Degrada√ß√£o previs√≠vel mas significativa com alta carga

### Hash Duplo  
- **Complexidade Te√≥rica**: Similar ao rehashing, mas com melhor distribui√ß√£o
- **Complexidade Pr√°tica Observada**: **Comportamento bimodal** - O(1) para Œ± ‚â§ 1.0, O(‚àû) para Œ± ‚â• 1.0 em alguns casos
- **Risco Pr√°tico**: Sensibilidade extrema a implementa√ß√£o e qualidade das fun√ß√µes hash
- **Confiabilidade**: Baixa para aplica√ß√µes de miss√£o cr√≠tica

## An√°lise de Trade-offs e Recomenda√ß√µes Baseadas em Evid√™ncias

### Para Aplica√ß√µes com Tamanho Conhecido e Œ± ‚â§ 0.7
**Recomenda√ß√£o**: HashDuplo
- **Justificativa Emp√≠rica**: Performance superior em inser√ß√£o (29.975 ns para 1.000 elementos)
- **Cen√°rio Ideal**: Tabelas com capacidade conhecida e fator de carga conservador
- **Risco**: Requer testes rigorosos em produ√ß√£o

### Para Aplica√ß√µes com Tamanho Imprevis√≠vel ou Œ± ‚â• 0.8  
**Recomenda√ß√£o**: Hash com Encadeamento
- **Justificativa Emp√≠rica**: Robustez comprovada (apenas 8.7ms para 100.000 elementos)
- **Cen√°rio Ideal**: Aplica√ß√µes gen√©ricas, sistemas com carga vari√°vel
- **Vantagem**: Toler√¢ncia excepcional a alta carga sem degrada√ß√£o catastr√≥fica

### Para Aplica√ß√µes com Restri√ß√µes de Mem√≥ria
**Recomenda√ß√£o**: Hash com Rehashing
- **Justificativa Emp√≠rica**: Performance aceit√°vel para Œ± ‚â§ 1.0 (42.8ms para 100.000 elementos)
- **Cen√°rio Ideal**: Sistemas embarcados, aplica√ß√µes com mem√≥ria limitada
- **Trade-off**: Performance consistentemente inferior ao encadeamento

## Li√ß√µes Aprendidas e Insights Cr√≠ticos Baseados em Dados

### 1. A Import√¢ncia da Robustez sobre Performance Pico
**Insight**: O encadeamento, embora nem sempre o mais r√°pido em condi√ß√µes ideais, demonstrou ser a estrat√©gia mais confi√°vel.

**Evid√™ncia**: 
- Varia√ß√£o de performance: 76√ó (encadeamento) vs 104,857√ó (hash duplo)
- Zero casos de degrada√ß√£o catastr√≥fica
- Performance consistente atrav√©s de todos os tamanhos

### 2. Sensibilidade n√£o Linear das Estrat√©gias de Rehashing
**Insight**: Rehashing e HashDuplo exibiram comportamentos altamente n√£o-lineares que dificultam a previs√£o de performance.

**Evid√™ncia**:
- HashDuplo: transi√ß√£o de melhor performance (1.000 elementos) para pior performance (100.000 elementos)
- Rehashing: aumento de 52 para 2,243,940 colis√µes (43,152√ó aumento)

### 3. A M√©trica de Gaps como Indicador de Qualidade
**Insight**: A an√°lise dos gaps provou ser um excelente indicador antecipado de problemas de performance.

**Evid√™ncia**:
- Tabela 1.000: gap de 797 ‚Üí performance inconsistente
- Tabela 100.000: gap de 1-11 ‚Üí performance robusta (encadeamento/rehashing)

### 4. Trade-off entre Performance Ideal e Previsibilidade
**Insight**: Estrat√©gias que oferecem performance excepcional em condi√ß√µes ideais podem falhar catastr√≥ficamente em cen√°rios adversos.

**Evid√™ncia**:
- HashDuplo: 29.975 ns (melhor) vs 3.144.902.200 ns (pior)
- Encadeamento: 114.741 ns (3¬∫) vs 8.710.984 ns (1¬∫)

## Conclus√µes Finais Baseadas em An√°lise Emp√≠rica

### Performance Geral por Categoria

**üèÜ Melhor Performance Geral**: Hash com Encadeamento
- **Vencedor em**: 6 das 9 categorias de tempo
- **Performance mais consistente**: Menor variabilidade entre tamanhos
- **Toler√¢ncia a alta carga**: √önica estrat√©gia sem degrada√ß√£o catastr√≥fica
- **Cen√°rios vencidos**: Busca (3/3), Inser√ß√£o em alta carga (1/1)

**ü•à Melhor Compromisso para Carga Conhecida**: HashDuplo  
- **Performance superior em**: Inser√ß√£o em carga baixa/m√©dia (2/3)
- **Requer**: Cuidado extremo na implementa√ß√£o e teste
- **Adequado para**: Cen√°rios controlados com Œ± ‚â§ 0.7
- **Risco**: Degrada√ß√£o imprevis√≠vel em alta carga

**ü•â Solu√ß√£o Conservadora**: Hash com Rehashing
- **Performance**: Previs√≠vel e controlada
- **Vantagem**: Menor overhead de mem√≥ria
- **Adequado para**: Aplica√ß√µes com restri√ß√µes de mem√≥ria
- **Limita√ß√£o**: Performance consistentemente inferior ao encadeamento

### Tabela de Recomenda√ß√µes Finais Baseada em Evid√™ncias

| Cen√°rio | Recomenda√ß√£o | Justificativa Baseada em Dados | Performance Esperada |
|---------|--------------|--------------------------------|---------------------|
| **Aplica√ß√µes Gen√©ricas** | Encadeamento | Robustez comprovada, toler√¢ncia a alta carga | 8.7ms/100k elementos |
| **Sistemas Cr√≠ticos** | Encadeamento | Zero degrada√ß√£o catastr√≥fica | Performance previs√≠vel |
| **Carga Conhecida Œ± ‚â§ 0.7** | HashDuplo | Melhor performance em condi√ß√µes ideais | 29.975ns/1k elementos |
| **Mem√≥ria Limitada** | Rehashing | Menor overhead, performance aceit√°vel | 42.8ms/100k elementos |
| **Alta Carga Œ± ‚â• 1.0** | Encadeamento | √önica estrat√©gia est√°vel | 3.7ms busca/100k elementos |

### Recomenda√ß√£o Final

Para a maioria das aplica√ß√µes pr√°ticas, **recomenda-se fortemente o uso de Hash com Encadeamento** devido √† sua robustez comprovada, performance consistente e toler√¢ncia a condi√ß√µes vari√°veis de carga. As estrat√©gias baseadas em rehashing devem ser reservadas para cen√°rios espec√≠ficos onde:

1. O tamanho m√°ximo √© conhecido com certeza absoluta
2. O fator de carga pode ser mantido conservadoramente abaixo de 0.7
3. Existem restri√ß√µes severas de mem√≥ria
4. Foi conduzido teste rigoroso em condi√ß√µes de produ√ß√£o

## Como Reproduzir os Experimentos

### Pr√©-requisitos
```bash
# Java
java -version  # JDK 8+ requerido

# Python (para an√°lise)
python --version  # Python 3.6+ requerido
```

### Execu√ß√£o Completa
Entrar no IntelliJ e rodar o c√≥digo `main` no arquivo [`Main`](src/Main.java) 
```bash
# 1. Gerar gr√°ficos e an√°lise
python -m venv .venv
source .venv/bin/activate
ou no windows
.venv/Scripts/activate.bat

cd plots
pip install -r requirements.txt
python plot.py
```

### Estrutura de Sa√≠da
```
plots/
‚îú‚îÄ‚îÄ 1000/
‚îÇ   ‚îú‚îÄ‚îÄ tempoInsercao.csv
‚îÇ   ‚îú‚îÄ‚îÄ tempoBusca.csv
‚îÇ   ‚îú‚îÄ‚îÄ colisoes.csv
‚îÇ   ‚îî‚îÄ‚îÄ maiorGap.csv
‚îú‚îÄ‚îÄ 10000/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ 100000/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ plots/
    ‚îú‚îÄ‚îÄ [gr√°ficos por tamanho]
    ‚îî‚îÄ‚îÄ [gr√°ficos comparativos]
```

## Limita√ß√µes e Trabalhos Futuros

### Limita√ß√µes Identificadas
- Comportamento an√¥malo do HashDuplo requer investiga√ß√£o mais profunda
- An√°lise limitada a tr√™s tamanhos de tabela espec√≠ficos
- Testes realizados em ambiente controlado √∫nico
- Conjuntos de dados sint√©ticos podem n√£o representar cen√°rios reais

### Melhorias Futuras
- Implementar redimensionamento din√¢mico para estrat√©gias de rehashing
- Investigar a causa raiz da degrada√ß√£o do HashDuplo
- Testar com conjuntos de dados do mundo real (nomes, endere√ßos, etc.)
- An√°lise de consumo de mem√≥ria mais precisa com profiling
- Testes em diferentes ambientes de hardware e JVMs
- Implementa√ß√£o e teste de fun√ß√µes hash adicionais (MurmurHash, CityHash)

## Autores

Renan da Silva Oliveira Andrade (renan.silva3@pucpr.edu.br)

Ricardo Lucas Kucek (ricardo.kucek@pucpr.edu.br)

## Tecnologias Utilizadas

- **Java SE**: Implementa√ß√£o das tabelas hash
- **Matplotlib**: Gera√ß√£o de gr√°ficos
- **Pandas**: An√°lise de dados
- **NumPy**: C√°lculos estat√≠sticos

---

*Este trabalho comp√µe a nota do RA3 da disciplina de Estruturas de Dados. Implementado seguindo rigorosamente as especifica√ß√µes fornecidas, com an√°lise emp√≠rica abrangente baseada em dados reais coletados experimentalmente. Os resultados revelaram insights valiosos sobre o comportamento pr√°tico de diferentes estrat√©gias de tabelas hash em cen√°rios do mundo real.*